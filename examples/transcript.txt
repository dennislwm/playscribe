excellent well good morning afternoon evening folks uh 
welcome to namal-session number one on February 23d today 
we have Scott Hansen talking to us about-terraform 
integration in gitlab I believe correct yeah awesome thanks 
take-it away Scott yeah so-um so gitlab can handle um the 
or or can can store your terraform back in so you-can 
essentially use gitlab as a or your terraform State files 
should say so you-use gitlab as a terraform backend so you 
don't have to worry about offloading any-of your state 
files to uh terraform cloud or um S3 or any any other kind 
of-storage um uh domain and so what we're going to walk 
through is just the-functionality within um gitlab that 
does that there's also some um terraform-helper that GB has 
put out there um and there's documentation on that I'll 
pull-that up um and we can we can walk walk through it real 
quick it's it's super-simple essentially it's every 
terraform command you can think of with a gitlab-dash in 
front of it um and by default just the way that it works in 
a pipeline-is uh terraform a nits are inherited so you 
don't ever have to call a terraform-a knit um and that's 
purposeful um because you're pulling it from the-repository 
so um some of the files that are created via um ter from a 
nit-command are going to be there based on what you have 
marked in your um in your-repository to be to be actually 
committed or not committed um but um it-runs a terraform a 
commit just or terraform a knit just to verify-everything 
is there so it's kind of a redundancy of commands to to run 
that-we'll go through it here in just a second um let me 
get this project up-here there we-go screen okay can you 
see my my project-here yes okay so um this project is a 
very uh-just straightforward it's a Lambda function um and 
it's deploying all the-requirements to to deploy a Lambda 
function and um essentially give it a-response this one-um 
is super straightforward all it's going to do is come up 
with a random-number between one and six and it's going to 
say your dier resulted in right-and every time you refresh 
it you'll get a new number not a huge deal um it's-just 
enough to make Lambda function um and so kind of going 
through here real-quick I broke this down into two chunks 
of terraform and I did it because-um the est3 bucket that 
holds uh the the Lambda function right we want it 
to-maintain regardless of what branch you're on and so I 
don't want to include-that in my application terraform 
because if I do that then if I tear it down for-a feature 
Branch then I tear down the bucket as well right and that's 
where-production theoretically could be running um so 
instead I have a common-bucket that's where this terraform 
common comes into play um and again-super straightforward 
um this is just my connection this is the back end is 
HTTP-um and git lab will will interpret that as local 
essentially to to the uh to the-repository um and then my 
environment file essentially has what I'm doing-right this 
is the module am I doing a force destroy what the name is 
um and-then here's the actual common structure right now 
it's only an S3 bucket-creating an S3 bucket and that's it 
and then I'll use this for follow on-application changes as 
necessary uh for for the Lambda function um and then 
in-terraform itself this can literally be anything you want 
it to be um but-because I'm using a Lambda function I've 
got API Gateway um this S3 bucket-doesn't exist anymore so 
that can be ignored um I have Route 53 in place and-and 
some some variables of of that nature um and then all the 
variables as-well they're already preset if I go to my 
environments file I created here you-can see these are 
pulling VAR app version it's pulling these from um from-the 
the gab c yl um anything named TF um is going to be 
interpreted so I'm-pulling these in as TF app version TF 
domain prefix and TF S3 bucket we'll see-that here in just 
a second um and then in my gitlab CI yaml I have it 
broken-out into a few different yaml just so my brain can 
wrap my head around it and I-don't have a thousand lines in 
one file um this is kind of a common workflow-here 
essentially it just makes sure that you don't run merge 
requests and Branch-pyos at the same time um I'm including 
the application including the-authentication uh this is the 
terraform for the application and this is-terraform common 
this only runs if this flag is H the true this is a 
cicd-variable in the project um and that's more along the 
lines of um if you're-running this in in you know real life 
um that variable would only be editable by-maintainers and 
above and so you want to make sure like this isn't just 
sitting-inside the variables here because then you have the 
capability to destroy or-override buckets right from a 
feature branch and we don't want to to or even-on a commit 
inadvertently to to the the default brand um-so um in real 
application I would say your commment would sit inside of a 
its-own project right inside of a group but being that this 
is in my own private-space uh groups are impossible so I 
threw it all the same project and just-broke it down into 
two different two different terraforms um from 
that-perspective but you can see here where I have like 
domain prefix app version S3-bucket right TFR S3 bucket 
whatever and it it it will consume those as um as-variables 
inside of of terraform um and that's just based on the way 
that-terraform Works um kind of walk through this 
real-quick I'm using cache to Cache my terraform directory 
just so I have that-a ailable to all the downstream um um 
jobs so it's not having to do everything-um in whole every 
time but also to ensure that I have the same data from-job 
to job when I'm trying to deploy these pieces um the other 
EML pieces-here this is my application essentially I'm just 
packaging this thing up the zip-file and I'm putting it in 
this path and that's it right I could theoretically I-could 
upload this to three on my own uh from here but that 
doesn't maintain the-state of what's actually deployed um 
and so it's kind of-um if this is a large application then 
then it would be go ahead and upload-this to to S3 or what 
have you directly um doing it through terraform is going-to 
be a little bit slower but being that it's one zip file and 
as you saw it's-very small um I'm going to allow terraform 
to do it just so I don't have-to manage it I can just put 
it all together as I want um and then the-authentication 
I'm using the oidc token within uh for for gitlab and and 
AWS so-I've created it where this project can can do 
whatever it needs to and with-with certain controls inside 
of AWS and I'm just pulling that out um and putting-it into 
a specific place um and it's also being cached so um I can 
show that-cash here in just a second but essentially it's 
caching those those uh-credentials so Downstream jobs can 
Leverage that as well you could-theoretically also package 
them as artifacts and pass them along the-problem with 
packaging them as artifacts is artifacts can be viewed um 
directly-and the cach cannot all right you can't go to the 
the the cash directory it's-all encrypted um so you can't 
just download the cash from there you could-create a job 
that exposes it and all that but then that would be 
pretty-obvious of what's going on um and like I said 
terraform common it's just doing a-plan and apply and a 
destroy um it's just jobs that I have actually in the-other 
cim we'll look at here in a second and then I'm setting the 
environments-for this as well so this is just production 
common um and when it stops-if we stop it or we we you know 
run the destroy command it stops IT and and puts-into a 
stop state from an environment perspective for get-lab and 
then in here again these are my my um templated jobs 
essentially we'll-look at this in just a second this is 
kind of where the magic happens but it's-the same exact 
thing that's happening down here I'm planning for the 
the-application right it's a review app so it's it's 
ephemeral it's going to a-dynamic endpoint um and we can 
look at that once it runs but this is the review-app plan 
this is the production plan this is deploying the review 
app-deploying to production and then also destroying your 
review app and-destroying production if that's what you 
want to do um in real life you would-have controls around 
these based on your environment and certain people can 
you-know deploy to environments and click those buttons and 
need approval and all-that kind of stuff um it's my 
personal project so I didn't want to have to-bother 
somebody to say hey I'm gonna put you on here as an 
approver can you-please click this button so I can kind of 
do everything here not best practices-um but just for the 
demo piece of this that that it's it's-functional um so 
getting into the terraform plan essentially before I 
do-that I want to I want to make sure we understand the the 
caching mechanism-here um so the caching here is going to 
cach this terraform um. terraform-directory and it's ALS o 
going to be this adbs config path right this adbs-config 
path is being set here based on on uh what we need to 
do-because when you run it in pipelines your route 
directory where your AWS-config would normally sit is not 
going to be available to pass down via cache-um so you have 
to kind of of play the game a little bit and so that's what 
I-did for the authentication um is I put in a specific 
place and then I tell it-that my config path and and config 
files or whatever are in a different path than-the default 
and that allows me to use the Cacho that's what this is um 
here-and the key is based on the ref slug so um anything 
that's created like on a a-feature branch is only going to 
be available to that feature Branch uh same-thing with with 
u you know the the default Branch or what have you 
it's-only going to be available to whatever the branch is 
or the ref slug I should-say be the same thing for tags um 
but that's kind of the the caching mechanism-there um so if 
we look into these templated jobs here um I'm-changing 
directory to TF root and I have TF root set in my variables 
here right-uh so here's the TF root it's just terraform 
that's what it is in my code-so that's what I have I have 
set this would be based on what you um are going-to use my 
terraform state name is default um and that's just the 
the-default state name it's going to change based on the 
branch and the features and-all that um this image is the 
image that's being used this is the gitlab or-terraform 
image it's got everything already injected into it so I 
don't have-to install anything um and then this is just the 
the AWS CLI image as well and-I'm just variz all these so I 
can I can change them at the top level if I need-to down 
the um the rest of these are-pretty straightforward this is 
just the bucket name that's going to be created-um this app 
version here is can be whatever you want it to be if 
you've-ever worked with Lambda you know that just uploading 
a new zip file into an-est3 bucket even if the contents of 
it have changed you know drastically um-it's it's difficult 
from a terraform perspective to make Lambda say oh 
yeah-something magic has changed here let's do it right so 
really it's got to be a-version change um or you've got to 
to do some other other fun items I didn't feel-like playing 
with that in the terraform at this point in time so I'm 
just going-to change versions whenever I need to make 
changes as as kind of it would be-in the real world right 
something changed then then we're going to push a-new patch 
version happen all right so let's go back to the-actual 
What's Happening Here in terraform right so this is 
changing-directory to to the TF rout whatever you have it 
set as um this is going to run a-gitlab terraform plan 
which is going to give you your plan right is going 
to-Output to the screen so you can look at it in your 
output this plan. Json is a-piece that comes from um within 
the helpers for for gitlab-um it outputs a file right named 
plan. um and it puts it in the directory-this is just part 
of one of the helpers generally you could just use 
this-without a problem and there's no big deal because I 
have two different uh-terraforms or terraform um State 
files that are going to come out of this one's-going to be 
for Commons and one's be for my application I need to move 
this to a-location that is or change the name of it 
essentially to a to a name that is is-unique to to each of 
those so I'm just changing it to whatever the state name-is 
um and then I'm I'm adding it as an artifact so that 
artifact that that file-can get moved down um as necessary 
from a a um caching perspective but also like-I said it's 
or it's being cached but so the plan. cach is kind of a 
misnomer-it's not really a cache it's just a random file um 
but I am artifacting this-because I want to Output this um 
so this is going to give me a Terri for report-here and 
this is going to say based on you know whatever it is it's 
going to-give me the number of changes um additions 
deletions all that kind of-stuff so in a merge request it's 
extremely useful because you can compare-those things and 
we'll look at what what that looks like here in just a 
second um-the terraform apply again pretty straightforward 
I'm just going to change-director to my route and I'm going 
to move this file back because again this-isn't the default 
name so it's not going to look for this I could pass the 
file-names as I want to with apply and all that but it's it 
was just to standardize-it across the board it made it 
easier just to change the file name essentially-then do a 
tform apply um so this is just get live terraform apply 
again it runs-the whole gamut of things because there is a 
file Associated to it and by-default gitlab terraform looks 
for these these plan files um the supply doesn't-need to 
have a force or it doesn't need to have um you know any any 
approval-Associated to or to pass a file you could if you 
want to but it's not-required if you have the plan. cach 
file that came from this plan-Json and then there is of 
course the terraform destroy which is the same-exact thing 
G lab terraform destroy it does the same thing as ter resty 
uh-before we move on any questions I have uh something 
related to-the gitlab terraform IM much do you know if this 
gets uh like regularly standard-updated with uh terraform 
packages um it does and uh I can find-that image but also 
there are a lot of um customer contributions that come 
from-it as well so whenever there's like a version change 
or whatever people are-I've seen it quite a bit it's like 
hey there is this new functionality in this-version can we 
please whatever right and they put a merge request in to 
update-the version but there's a lot of a lot of pieces 
there that image has been very-reliable for me in the past 
um but again if it's not exactly what you need right-you 
have the capability to do to do other things right you can 
you can you-can build your own image as as you seeit um but 
it's you're going to-get it's from what I've seen it's it's 
it's in line with what you get if you-pull just a a a 
random terraform image right um that's what you're you're 
going-to get all the all the tested pieces and all the 
tested packages you're not going-to get anything that's 
like tip of the spear Cutting Edge-um go ahead what was 
that yeah all good thanks um and then this is uh these 
are-the terraform helpers um and you can dig through the 
documentation here um to to-see exactly what they're doing 
right but a teror form apply right you show is-there an 
implicit in it for the vast majority is there is for a 
format-there's not but that's not required either um but 
you can go through and-look and see exactly what is there 
um so again here's generic variables that-are already open 
to you and then there are the the manage State variables 
if-you want to use these you can you can use these for 
whatever you need in-terraform I didn't put all of these in 
there because I wasn't going to build-functionality just to 
demonstrate things that were were not useful to 
my-application um but you can also if you don't want to do 
the implicit nit you-can set this to false things of that 
nature right there's a lot of things-here that can you can 
go through and and dig through here's more items about 
the-the image here if you want to uh to look it up-uh but 
you can again it's it's all documented pretty well it's 
just a-matter of kind of putting all the the 
pieces-together so we've got all of those in place um like 
I said I'm I'm deploying a-review app um essentially what 
it's doing is just creating a file in the-same S3 bucket 
under that same version or whatever version is passed um 
and-then it's just a a dynamic URL um so um if you look at 
the deploy review-app you'll see that this is a dynamic URL 
that's going to be Associated um-happy. Tanuki or happy 
toni. click is just a a domain that I have access to um-and 
so that's where it's setting um and then I also have it set 
to Auto Stop So-if it's running from more than an hour it 
automatically just runs the stop-which that stop is this 
Destroyer view app which essentially does a 
terraform-destroy and it stops the environment um within 
gitlab so everything shows shows-us as shut down let's me 
look and see I think these-pipelines are cleaned up now 
I've been playing with this quite a-bit yeah everything's 
been destroyed oh this one's-not so that's fine this is 
common infrastructure that's like I said just-the S3 bucket 
we'll go ahead and leave that for now um I am going to 
change-this CSU very so it doesn't keep trying to deploy it 
or it's it's just going to-run terraform on it and go oh 
nothing changed um so you see I have this-variable set here 
for deploy Commons and right now set to True um you can set 
it-to to false it's only you can set it whatever you want 
it's only looking for-true it has to be true for it to run 
otherwise it's it does nothing um I'll-leave it here for 
now for the first time um but if I look at my pipelines 
here-I've got these broken out and they're kind of 
heavy-handed and very large-purposefully and that's just to 
kind of demonstrate everything that's going-through in each 
stage um this could be cleaned up and streamlined quite a 
bit-but that's not really uh what I want to show is you 
know how you can Mash all-these things together I want to 
show kind of the functionality of it so like-I said this is 
is pretty wide for for what we're doing here but this 
is-packaging the application just creating that zip file 
this is assuming that roll-um it's only good for an hour so 
if you don't run it within that hour you've got-to rerun 
this um assume Rule and that's why it said as a manual job 
so you-essentially don't run it until you're ready to 
deploy this is plan the common-infrastructure that's set 
as3 bucket for now that's going to deploy it this is-going 
to plan for production um this is going to deploy to 
production right and-then I can destroy production and 
destroy my common-infrastructure um right now destruction 
is or production's been destroyed right-but common 
infrastructure hasn't so if I look at my environments 
here-um production common is the only one that's here the 
other two are stopped-right one of them is going to be 
production and the other one is a a-review app that I I've 
got deployed right now but it's again in a stop State-um 
and then if I look at my terraform State-files here's the 
state files Associated to those um so like here's feature 
a-which is is it's currently there it's just in a stop 
State my default uh which-is my my application and default 
common again you can change the naming-convention based on 
on needs uh let me go to pipelines-here and I have this 
pipeline here for feature a that is done and it has 
been-destroyed okay good so we'll run a new pipeline so 
this is a new application-we're just getting up and running 
so our first you know main commit is going to-be our commit 
is going to be to the default Branch just to kind of 
initi-everything so let me just run that Pipeline and we 
will get that started I-could override that variable here 
for deploy Commons but I'm just going to let-it go for now 
um while this is running there's a few-manual steps I have 
to to click on here are there any any questions um from 
the-the what we we' spoke about so far uh another one for 
me um so the-infrastructure uh you're deploying um can I 
consider this like as a dep-environment so death deploy an 
S3 and test and then you do the manual process-of 
production deployment when you merge to prod or like um 
like so yeah we'll go-through that just a second right this 
this Commons is is not always going to-be included this is 
just an est3 bucket right this essentially is creating 
this-bucket here and that's it so you see there's nothing 
in this bucket it's just-the bucket just got created and 
that's essentially because all of the zip files-are going 
to go to the same bucket regardless of the environment 
right um-You may have a production bucket you may have a a 
you know whatever I have one-bucket and essentially it's 
all going to be based on the version I'll show you-that 
here in just a second um and and we'll make changes and 
push those-changes but this that that Commons is only to 
deploy that bucket that's going-to be used across different 
environments essentially so I don't want one-environment to 
deploy a bucket because if it does that then my 
production-environment would be you know if say I I take 
down my my uh ephemeral environment-right and I run a 
terraform destroy on it and that bucket was part of that 
then-that bucket goes away and my production environment 
could be part of that bucket-right so essentially it's like 
I said this theoretically would be in a-different project 
right but I just threw it all in-the same one um so it's it 
gives the capability to to leverage the same-bucket and 
you'll see there's actually a file structure that's going 
to come out-based on the version and and once we start 
deploying things you'll you'll see-those pieces here so 
this is the assume roll piece here um if you've not 
played-with with um with the the connectivity between AWS 
and and um and in gitlab it-makes things extremely nice 
again best practices wouldn't be the same use the-same role 
across everything because theoretically I could just make a 
role-that doesn't have the ability to create or delete 
buckets right and that that-would be the role that all 
other branches besides my default Branch or or-whatever the 
branch is deploying to to production right doesn't have 
that role-the only role that would have that is is you know 
the the role that can deploy-the production or what have um 
or a separate role by itself just to to-isolate it um but 
this role essentially has the ability to create S3 buckets 
and-it can list and and essentially everything with S3 the 
Lambda function-piece of it the um everything needed 
essentially to deploy your your your-Lambda function so 
this assume roll here while this is running let's just take 
a-look at this this is kind of a bonus not necessarily for 
terraform but it's just-a bonus here right so essentially 
it pulls everything down um it makes the-the the call DS 
and and and gets the the credentials as needed then I'm 
just-doing a get caller identity here um and so this tell 
me this is a user ID here's-the account here's the a right 
um and so these are all uploaded as as necessary-I'm just 
getting the caller identity here because you have to have a 
script-in a job um and that's essentially where-that's 
happening so I'm just getting that color identity we can 
look at that-more if you're if you're interested and you 
have-time um so like I said this is just planning the 
common infrastructure it's-running a git laab terraform 
plan um there's G to be no changes-here so it's really 
going to Output nothing um because there's like I said-no 
changes in this plan so as you can see it ran getl terone 
plan it-initialized everything because a knit is inherited 
um and here's the modules-there's no changes right so it's 
going to go ahead and move on then it's going-to do the 
plan Json to get the cache file um but there's nothing 
nothing to-be changed so it's just going to pass through 
and then this would be deploying-the com infrastructure 
again it's creating an S3 bucket it already exists-so it's 
going to say no changes and it's going to move along 
as-well and let me show you over here under uh 
the-environment so when you stop an environment especially 
an Emeral-environment it will stay here so this one is just 
for my feature a branch-right but if I had a feature B 
Branch or a feature whatever or bug fix it would-be here 
and once it's stopped even though everything's been 
deployed or-everything's been destroyed this would stay 
here so that's one item that would-need to be cleaned up 
you can clean it up VI an API call or you can clean it 
up-in the UI there isn't a inherited function inside of 
gitlab CI that just-says and delete the environment that 
that that it's not part of the part of-the the 
functionality you would have to do a v-API then also we 
already go through the state files here-yeah so I've 
deployed these before right and you can see when they got 
deployed-um and then this one is is there's no update to it 
so it's not going to change-anything you can delete these 
you can download these um it's actually super-useful if 
you're going to be um working on your local machine and you 
want to be-able to to um test out your your terraform 
locally prior to any push into-pipeline you can get this 
terraform AIT Command right here with your access-token 
essentially allows you to to run all of this from your 
local machine as-well so you don't have to have to try to 
try to square peg round hole it uh too-much right it gives 
you a lot of the information um and this will set you 
up-from the NIT perspective to work locally with with 
terraform or with get lab-asure terraform back in all right 
let's see what this is-at all right so this is the plan I 
can take that plan off it doesn't need to be-manual I don't 
know I got that manual fix-that but while this is running 
and deploying I'm going to go back to-um so in this feature 
Branch I've made I made uh a couple changes-here that's 
Branch um I made a change to the-application right so 
essentially I had a date in there that I took out that 
just-says and was issued at now um and put where it's just 
random number so I'm G-to I'm going to edit this and I'm 
going to redeploy this feature-and then I'm going to open 
up an emerge request and I'll show you what happens-there 
um-okay all right so we're going to see another pipeline 
kickoff here-and this is going to be for my my feature 
Branch let me go ahead and-deploy this to production um 
this is going to be for the the feature Branch-here right 
and this obviously has a few a lot less stages in it 
because it's-just doing a plan and a deploy it's not 
worrying about the common files it-expects that S3 bucket 
to be there if it's not there of course it's going to-fail 
it has nowhere to write the S3 or write the zip files too 
so it would it-would fail um but this is uh going to 
essentially deploy this well the Deploy-on the on the 
branch side is manual right and that's just way I have it 
set-is so if it if you do a commit then you may not want to 
deploy it to to the-environment right you may be working on 
other things and just trying to to make-sure that that the 
plan is functioning or what have you um and you can 
manually-deploy it via this this Branch um but I'm going to 
open up a merge request-once this is done and we can kind 
of see what functionality happens there-and I'm not using 
any special Runners here I didn't actually specify 
any-runners I'm running just the the ones that are offered 
by by gab so you can-see this is running a ter from apply 
here and it's running in a nit as it-does um and then it's 
creating all these all these resources right so there's 
an-IM roll that that is going to be created API Gateway the 
objects being uploaded-if we go look at this bucket here 
and I refresh it you'll see now there's a-version here 
right that's the version that got passed and then inside of 
this-app. ZIP is just what I've named my one for my my my 
application that's deployed-to production when we deploy it 
uh into like a feature Branch you'll see that-there'll be 
another file here that is named differently um let me just 
make-sure there's Route 53 records that are being injected 
and API Gateway stuff and-everything else so I'm not going 
to I'm not going to bore you with that unless-you aren't 
super interested in requirements for a lamb to-function ass 
yeah-it's it's uh it's a fun process if you've never been 
through it there can-be a lot of gotas depending on your 
application um so again this is going to-deploy it to to 
this for feature a and this there'll be a different URL at 
the-end of the pipeline um it's going to Output your your 
URLs I just have that-as as being returned um we'll see 
that here in just a-second so this has to create Route 53 
records and because it's creating Route-53 records uh 
there's a weight essentially that's built into um 
it's-built into um the terraform I have that says-wait till 
this becomes available so it's looking for that record to 
come up to-say yes okay it's it's reachable now um before 
it does anything else so right-here you can see for the 
serverless app this is the API Gateway based URL so if-I 
look at this I can open this up in a new tab and this is 
going to say your-dice store resulted in a four right I can 
refresh it all day long and it just-gives me a different 
number um but also this is my actual application Ur in 
or-or URL right if I was actually like running an 
application this is where I-would go and check out that 
application because this is just a simple returning-a 
message right this is all you're going to get the same 
exact thing it just has-Route 53 in front of it so you have 
a a an end point any of but any of y'all can-go to this 
endpoint right now and do the same exact thing and get a 
random throw-a dice um he let's go back-here let's see 
where this one is just just a second um but you'll see-here 
in this bucket there's app. zip right so now if I look at 
this there's a-feature a.zip that's the that's that that 
feature Branch so that's-essentially the the Lambda 
functions you be looking for that um based on on the-needs 
of that if I go to Route 53 you're going to see that 
there's Route 53-entries that got put in right again that's 
all Lambda stuff that that we can-dig into if if necessary 
but uh let's here we go so this is again-same thing now 
this is showing oh we got a-two and was issued at right and 
gives us a date cool cool super cool update-whatever it may 
be um and it gives me this ephemeral URL as well this 
gets-created um I should say Dynamic URL this gets created 
on the Fly based on what's-necessary NE for your 
application is using the branch name as a naming-convention 
to get that URL running um you can tie it back however 
you-um but now that we have um those that change in 
place-um let me open up a merge request here I'm want to go 
from Branch a to-Main yeah I'm not going to really 
put-anything in here because I'm not super worried about it 
right now-um okay so a merge request pipeline is going to 
run for this as well on the-merge request pipeline um it's 
going to essentially redeploy this application um-if you 
open a merge request when you open the branch then it's not 
going to-rerun that pipeline it really is dependent on on 
you know your-application and how you you know your team 
Works um but this is going to run a-merge request if I push 
a commit to the brand it's not going to run a 
branch-pipeline it's just going to rerun this merge request 
pipeline um and and update-it so if I see there's an error 
or something that that may be there um-that's going to show 
up because this is a review app it sees that based 
on-naming conventions I can just click on review-app right 
and it goes to to that endpoint so you can preview it 
however-you see fit but once this runs we're going to have 
uh some output here from-our terraform plan um I have it 
set to actually run the plan for production as-well um so 
you can compare the two to make sure that the changes 
are-associated between those two items um and and you 
you're not making like you-know 5,000 changes to production 
that are unintended um we'll look at that-once it once it 
gets that point and then also this merge request-won't 
allow you to because I have it set that pipelines must 
succeed-um this will not let you merge it until you 
actually stop the review app which-means that it tears down 
the environment right so it does a tear from destroy on-the 
Emeral environment let-me go in here I want to make one 
more change just so we can run that pipeline-as a merge re 
with pipeline again this is going to be in my gepsi Amo and 
this-is just to update the the terraform um I'm going to 
edit this directly-shouldn't really be doing this but 
whatever uh-um I'm in the wrong branch that would have been 
bad news-huh all right there we go and so I'm going to 
change this to-1.0.2 um we made some minor tweak right all 
right let's go ahead and-change that-um all right so if I 
go look at pipelines here-all right this one's still 
running from that that previous merge request because-it's 
deploying if this was sitting in deploy and this got to 
deploy um I have-resource groups identified so it's not 
going to allow that deploy to happen at-the same time right 
only one of those is going to run so this one will have 
to-complete before this next one would pick it up is 
essentially how that that works-I'm I'm leveraging the 
resource groups I don't I know if you saw that inside 
the-yaml let me show you [Music]-here um there we-go if you 
look like this I've got this Resource Group right here 
right so-actually I didn't set it up for for review app so 
just kidding forie up that-wouldn't happen for production 
that does happen so there's a resource Group here-so if 
there are multiple merge requests that go to production 
fairly quickly um-which essentially is commits to that 
Branch uh it's not going to allow these-to run concurrently 
it's going to they have one has to complete before the 
next-one would run um and so if you do that for your plan 
and for your your um-deploy um and even for your destroy 
and can ensure that your environment-essentially is not 
being overwritten by another commit that comes to 
that-Branch let's see where we're at okay but now you can 
see I've got three-environments that are running here um 
this one's production right and I can I-can click open and 
it's going to go to the the URL there and you can see 
what-it currently looks like and then um I can go to 
feature a and you can see what-it currently looks like from 
our change um and then I'm just waiting for this-merge 
request to finish deploying which is-going to be should be 
fairly quick because there's not much that needs to-be 
changed this is really great I liked it a lot-that you 
combine it with environments and cash because the standard 
terraform-templates I think gab provides um being that's a 
good point-they're deprecating them because they're they're 
they're they're minimal as-intended but they're super 
minimal right they don't really get you very far by-using 
those templates yeah exactly so you have for-example 
destroyed as the uh manual Step at the end Etc so I I 
really like that-that you combine this with uh environment 
Destroyer which like the-moment you stop the environment 
that it does the destroy for example for the-future Branch 
yeah so I can destroy here I can go back to the pipeline 
and click-destroy I can click the stop button here I can go 
to the environment and click-the stop button it's all the 
same functionality um but you can see right-here there's 
two terraform reports are generated by-pipeline um and this 
one is for my review app right and it's saying okay-one 
thing was added one thing was changed one thing to delete 
whatever-that may be you can go to the full log here and 
that's going-to to send you back to this essentially right 
back to the log and you can look-at the things that were 
changed um and then this is saying okay from this these-are 
the changes that are going to be going to to um production 
right and so-you again you can go back and and look at the 
full log here and you can look at-the the changes that are 
associated to that because this is running just a-terraform 
plan this isn't running anything else but you can see 
what's-going to what's going to change in in the 
environment right so essentially you-can see that I'm I'm 
going from 1.0.1 to 1.0.2 right it's changing that 
that-version there so if I look in my bucket here-now right 
I only have app. zip here in 1.0.1 in-1.0.2 right feature a 
is moved over to there because it's it's changed that-that 
version there so it kind of gives you the ability to track 
um if you-wanted to maintain these zip files long term then 
my my real suggestion would be-to to Leverage The the 
uploading inside of your pipeline as opposed to inside 
a-terraform right because terraform is either going to add 
it or delete it it's-not going to ignore it-um so you can 
look at those changes there but that gives you a quick 
look-here that says hey here's here's the the addition 
changes and deletions that are-going to happen um and it 
says pipeline must succeed so I can't even merge it 
in-until I kill this environment so I can stop the 
environment here that's going-to run that last that last 
stage uh on on the pipeline here which is going to-destroy 
that review app and I'm just going to set this to Auto 
merge so it-kicks off after the fact um and then we'll see 
all that update kind of-trickle down U because the merge 
request will be accepted and then essentially-that those 
changes get committed to the uh the default branch which is 
the-branch that deploys to production um and then if I look 
at my environments-here let me refresh this so I've told 
this to stop you can-see how this is showing Auto Stop in 
57 minutes right because I have that set up-so if you open 
up a merge request and nobody looks at it then within an 
hour-it's going to take that environment down because you 
know it costs money um and-you can go back and and redeploy 
it through the pipeline or what have you-this shows you 
where it was last done so you can actually click on this 
and rerun-it you can go back to your merge request and 
rerun the pipeline there's a million-ways to redeploy the 
environment um but this is is showing as there is no 
stop-button here because it's in a stopping state so it 
doesn't go to stopped until-it's actually stopped uh that's 
why it's still showing is active because you-can't stop it 
but also at the same time it's not stopped so it's kind of 
in a-weird interim State um and once that that pipeline is 
done here-uh destroying all the all the resources and again 
it shows you everything it's-going to destroy um then it'll 
merge that that-piece in that environment um will go to to 
stop and it'll show in this tab here-then again if you 
don't need it anymore you can just delete it um-because 
that's one thing I was going to add in but I didn't get 
around to it was-making the API call on Destroy actually 
delete the environment to because this-is no long it's no 
longer needed right even if it's in a stop State 
you're-going to end having you know a thousand environments 
here that that show up so-just for cleanliness it would be 
one of those things You' want to clean up over-time any 
questions uh so far we're getting towards the end-here is 
there any way to um to automate um the deployment why are 
the report-results so are there like um numbers of uh added 
resources from the-terraform plan is there any way to 
automate like how many reviews it's it-needs um or stuff 
like that based on approval that yeah exactly yeah so 
you-can because this is in my own personal name space right 
I don't have a whole-bunch of other groups so this got 
merged right that finished so this is merging-um but you 
can have merge request approvals on here right so you can 
say-um I can create a feature Branch all day long and I can 
open merge request-against it sobody can review it right 
but I need at least somebody from my QA-team and I need 
somebody from you know I need my manager to also agree on 
it-right and you put a merge request approval in there so 
this merge wouldn't-happen until those two those at least 
you can have as many as many merge-request approval 
requirements as you need but this wouldn't happen until 
that-merge request approval goes through then once it does 
go through it'll deploy or-are you talking about manual 
deployments to ephemeral environments no no I'm I'm-talking 
about um can you set a review based on the changes made in 
in the-terraform so the terraform plan spits out um one 
want to delete so can I put-some reviews on it like-um 
based on on the the reports generated in the-pipeline so if 
something is getting deleted that's uh maybe an an 
resource-we need so maybe need some reviewers but if there 
are some add addings only uh we-don't need additional 
reviewers I don't think that-functionality exists um Glenn 
or Aaron do you do you know I don't think you can-you can 
say based on on this finding I think it's either there's 
approvers or-or not I know that you can throw certain Flags 
to include approval groups based-on on environments or what 
have you um or or necessary groups but I don't think-it can 
be done based on the out of the reports yeah not that I 
know but if I-understand correctly if if I'm deleting X 
make somebody make this person review-it or if I'm deleting 
just in general make this person review otherwise 
they-don't need to I don't yeah I don't think there's 
anything like that but the-closest you could get kind of 
what Scott was talking about would probably be-something 
around code owners where you could say yeah this specific 
module if-something changes here make sure this person 
knows but that's about it that-was my next suggestion is 
code owners right you can have your storage team-right 
they're the ones that that are code owners of of anything 
that's in-that storage module um and if something changes 
there they get-notified all right yeah we do not have I 
think such-functionality also for other things like junit 
tests or whatsoever that there is-a okay something failed 
at another approver maybe via API you can do-something but 
like a work around yeah you would have to like-Leverage 
custom attributes and have that checked in the pipeline 
that you know if-this is there then this custom attribute 
you know there's a lot of things you can-do there but 
that's all that's not natively built in as a function you 
can-just use right you'd have to build all those um it's 
just like the same thing-you could actually I mean if you 
wanted to you-could take the output put it into uh a 
certain format and actually export it as-like a 
vulnerability and have that type of vulnerability set to a 
certain team-right so it really looks like a security 
vulnerability than anything else um but-it would but it 
would then automatically trigger an approval from 
that-group um but that's kind of a workaround that I 
wouldn't suggest because now-you're in in injecting 
security vulnerabilities that aren't actually-security 
vulnerabilities um but the code owners piece is really the 
the the piece-that that needs to be known because it's 
going to be the the changing in deletion-right and they're 
the ones that would need to be notified of it so it 
would-have to be changed in that in that that module um 
actually that's a good point-because it really could be 
changed via a variable as well and that wouldn't-change the 
code in that in that module so that would catch like actual 
like-code changes but from like uh I'm changing the name of 
my bucket really-that would be more of a of an approval 
that would need to be set as emerge-request approval right 
your how's your infrastructure team looked at-this yeah 
that's a good question though I don't it doesn't go it's 
kind of a uh-um approve the merge request or don't approve 
the merge request not really-based on on what changes are 
happening in terraform it really is only going to-be based 
on what changes are happening in the code-yeah so this is 
deploying the the production pipeline right now um and-it's 
it's oh I forgot to set that that flaggy-in so 
theoretically I would have set that to false right so you 
don't have to-worry about that bucket ever being looked at 
again until you actually need-to change it um or delete it 
um but that's currently running and then it'll-do the plan 
and create and deploy and all of that fun Jazz if I go back 
to-environments yeah it's updated right so it's showing is 
stopped now so this-branch no longer exists so I would like 
to make an API call right that says-delete this environment 
um but it's not there so I'm going to make-the uh the API 
call with my finger and click the-button and that'll just 
get rid of that that environment there-so again it's no 
longer there and if you wanted to if you wanted to clean 
up-these environments be the same thing so like here's 
production right this is is-currently waiting uh for 
destroy this is from a previous run um so this got-deployed 
and it says it's waiting because the next step is to deploy 
the-INF or to destroy the infrastructure um but this is my 
my latest deployment-here um see-at okay let run that all 
right I think you guys have-kind of see the purpose here um 
any any other thoughts or concerns or questions-or or write 
it right about it time here and I I don't want to go-over 
that was great thank you very much yeah it was great thank 
you is-there any way uh this is published uh can we-use 
demo yeah let me let me drop it in the chat here I metioned 
that in the-beginning and I didn't yeah it's public there's 
a few things that are only if-you're members of the project 
it's in my own personal space um Glenn I imagine we-can 
probably find a place to put this um maybe we need to 
create a new group or-something that's that's you know 
Associated to this call every week or-every every other 
week yeah I know we talked about that before I think 
leopard-has a place I'd have to I'll have to ask him and 
see where you can stick that-okay yeah because we can just 
move it over there um but again this is tied-back to my ads 
account um and so I've got the I've got controls on there 
to-unless you're a member you can't really do anything you 
can look at it but you-can't really do anything um because 
I don't want it I don't want-it you know all over the place 
don't want a public uh public project that's-GNA cost you 
$20,000 a month yeah so I mean it's running on Lambda right 
so-it's really not that that that bad but I mean you could 
deploy as many branches-as you you want to all right let me 
run this-here um so one quick thing right you'll see 
here-is is I deleted that that uh that ephemeral 
environment right the one do-0.2 went away because it's no 
longer there again that's the problem with with-uploading 
to to buckets uh via terraform is if it's not there it's 
not there-right it's going to get rid of it it's not going 
to let let it let it linger um-you could turn the for 
destroy off but then you're going to run an error in 
in-terraform so um once this uploads as well you're going 
to see that this-version is going to change this folder 
will go away the new folder would be-1.0.2 and you'll see 
that app directory in there as-well all right that's going 
to deploy then we'll be done um yeah so that's-just going 
to going to upload to the S3 bucket and go from there the 
vast-majority of the pie are already there so it's it's 
going to look at it and go oh-all of this is fine um and so 
it's just going to to to upload the uh the file-make a some 
some minor changes within within Lambda and then it's going 
to be-redeployed if I can get this pipeline to go we got 
one minute come on-Pipeline but yeah this should be should 
be fairly quick-yep there we go so it's already run we just 
haven't gotten a report back from-the runner there we go 
already succeeded so you can see it changed the folder 
and-and there it is um and then if I go look at my 
environments here here's-production I can open this up and 
now it's got that change that we-pushed right fun times so 
thanks for B time I really-appreciate it let me know if you 
have any questions or if you need more access-to that 
project or what have you awesome thanks again Scott really 
appreciate it-yep absolutely take so much thanks Scot by
