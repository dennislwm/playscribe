come on oh live live this isn't even like-recorded and 
uploaded good stuff all right ready yeah go for it 
all-right folks so uh today I'm going to talk about 
something easy and simple um-reference architectures so 
these are gitlabs-um architectures and uh couple things 
today we're going to cover are just I-want to cover some 
key Concepts uh talk about single node versus ha when-to 
use them we're going to go through some gitlab components 
on the servers so-when you we get into the slides later 
you'll see that gitlab is quite a-complex stack with a lot 
of pieces and so I just want to talk through each-piece and 
what its function is and then we'll start talking about the 
reference-architectures themselves so we'll look at a 
traditional 3K uh a cloud 3K using-cloud services Cloud 
native hybrid 3K then we'll move on to get like Gio-talk 
about that what it's used for what it does and does not do 
and then the-final slide is just a getting started with get 
and I think there's another-enablement session that'll 
actually get into the details of how to deploy a-reference 
architecture please feel free to ask-questions and 
interrupt as we go along as well-um so the first thing and 
uh you know Brian put this in I think this is a good-slide 
just to start with real quick but uh gilb has three 
offerings we do-self-managed which is what we're going to 
focus on today and then we also have-a get laab dedicated 
which is self-managed but G laab dedicated set-and then 
gab.com which is our SAS offering all right key Concepts so 
the-first thing I want to discuss is Omnibus and I think 
that gets thrown around and-sometimes folks get confused 
when we use it but what Omnibus is is it's gitlab's-bundle 
package so includes all the installers for all the services 
that we-talk about today and a few that I didn't include 
because they're not as commonly-used so when you install 
gitlab on servers-you get one file it's an rpmm file and 
that one file can be used to install any-service Rus a post 
scratch we'll get into all them later and how it works 
is-you install the M file and then there's a configuration 
file called to get laab-RB which is an ety gitlab gb. RB 
and the configurations that you make in there-determine 
what that node is and how that node gets configured so I'm 
going to-pull up an example real quick and this is what 
I-use when I'm trying to figure out how a service gets 
configured so this is I-don't remember how many lines of 
code it's huge but let's say you wanted to-install 
postgress if you go into this file and-you uncomment out 
postgress enabled equals true this node now 
installs-postgress um and alternatively you have to tell it 
not to install Services too-right so if you don't want post 
crash you would have to set postc crash to-false High 
availability so high availability-is your infrastructure um 
being designed in a way that can tolerate outages 
uh-without degradation or um performance hits so with 
gitlab we can deploy within-region High availability uh but 
we cannot do high availability outside the-region without a 
loss of uptime and we'll get into that when we talk 
about-Gio and what Gio does and its limitations uh the 
other thing I want to-discuss here too is is when QA does 
the reference-architectures they use the Expression double 
double meaning when you talk to-grant for instance he'll 
say that our reference architectures are double-double if 
we say it's a 2K reference architecture it can support 
8,000 users-more than likely on a standard load um but the 
idea is is that if we want ha we-want to make sure that we 
can tolerate outages without degradation performance-so if 
half of our infrastructure goes down we don't want the 
other half-getting hammered by the users we want them to 
still feel like they're's up and-running and everything's 
good so um our for most standard customers our-reference 
architectures are Overkill they are very large but 
they're-intentionally designed that way so that they meet 
the ha qualifications-requirements and then Dr is uh how we 
handle catastrophic outages right so if-you're in AWS for 
instance what happens if Virginia falls in the ocean um 
you-know that's where everything started that's that's 
Netflix right-uh so how does a customer get their Source 
back and gitlab solves this-problem with goo and I think a 
lot of times customers get confused between ha-and Dr and 
what requirements and what gitlab products uh solve for 
those-problems then the only other two things I want to 
cover that come up a lot in-calls with customers is RPO and 
RTO so RPO the recovery Point objective is in a-disaster 
scenario what is the recovery point in-time that we can hit 
right so if you think about nightly-backups for instance if 
you're running a backup nightly your recovery point in-time 
has to be 24 hours because you're only running one back of 
that instance-every 24 hours if you're doing hourly 
snapshots you can hit a you know one-hour RPO so and if you 
use Geo and we'll talk about this later uh your RPO 
is-closer to 15 minutes or real time because you're 
constantly streaming that-data to another region recovery 
time objective is the maximum amount of time-that your 
organization could be down until you covered so how long 
does it-take your sves to get git lab back up and running 
um as soon as it's outage-any questions on these no cool 
all right-um I think the next slide kind of talks about a 
little bit more and we'll go-into it but um you know 
there's tradeoffs when you-talk about RTO and RPO the lower 
those numbers are meaning the less data loss-you're willing 
to accept and the faster you want to be up uh the more 
expensive-the infrastructure is so uh simple Disaster 
Recovery approaches are less-costly but carry a higher risk 
of data loss and system on avability-and we'll talk about 
that here so I want to kind of talk about a single 
node-versus a reference architecture right and Brian 
put-together a slide to talk about this uh it's like a 
table I like the images so I-put together a network diagram 
this is a 3K reference architecture with the 3K-Geo and 
this is about $60,000 worth of VMS upfront and I'll kind of 
get into-the cost and things like that how that works later 
but um you know if a-customer comes to us and they say that 
we need a 3K reference architecture and-it has to be highly 
available and we want a 3K reference architecture 
that's-highly available in the secondary region uh they're 
asking for 50 servers-and $60,000 worth of BU VM clost for 
the first-year so um the RTO and the are great with the 
solution but it's also-incredibly expensive and you have to 
have the staff to support-it for environment serving 2,000 
or few users gitlab actually recommends a-single node so if 
you go to the refence architecture documentation um you 
know I-think Professional Services historically has hit use 
the 1,000 user marker but-gab uh as a QA organization uh 
recommends-2K and then um just kind of go through 
the-advantages so if you look at the left side this is your 
primary site and you-look at the right side this is your 
secondary Geo site either one of these-can be a single node 
and support up to 2,000 users so you know by going with 
a-single node Geo for instance you're taking out a 
considerable amount of-infrastructure um but you're giving 
yourself a much easier uh infrastructure-to manage and set 
up uh you can use gitlab backups and snapshots at the 
same-time and uh you know the downside is you have a single 
point-failure sorry any questions on ha and we'll get-into 
the actual components and what they do out of curiosity do 
we have an idea-how much of this total infrastructure is 
represented by the database the post-gray infrastructure 
yeah I'll get into the components and on side 
but-absolutely so so this is the front end so your web 
servers this is your-Sidekick your background jobs this is 
your application database these six-servers right here this 
is your cache database this is your fover Sentinel 
and-console and then there's another database over for 
gly-cluster um and then on your secondary site there's an 
additional database for-tracking database for geo so a lot 
of databases involved yeah yeah just-thinking that maybe 
more modern databases might might provide some 
some-efficiency in this area but that's just a wild thought 
right nope you're not-wrong we'll get to that awesome Okay 
Kevin Kevin on the um on the secondary-site how hot is that 
how hot is it in order to fail over how long does it 
take-I'll cover that later but it could be done in 
15-minutes okay could you run could you run active active 
no yes and no and I'll-cover that later all right you're 
going more into I'll get into that yeah we-we'll we'll talk 
about Gio at the end um you know when you talk to 
customers-though yeah we we'll get into that in a later 
slide I don't want to like-undercut it but very good 
question so um I'm just gonna spend some time going-through 
the different services that run on these just so everybody 
knows um you-know these are the front-end Services uh 
sidekick probably shouldn't be on this-list I kind of group 
it with it and we'll talk about that later with-kubernetes 
um you know but if a customer comes to us and they say hey 
we want to-run gitlab and kubernetes these are the 
components that essentially get put into-kubernetes so um 
and then there's a diagram here on the architecture 
site-and we're talking about these groups right here and 
they're usually all on-the same node or in some cases split 
up so we have Puma which used to be-called unicorn and 
that's our frontend web server so Puma is uh when you go 
to-gitlab.com and you see the goey uh that's Puma rendering 
that for you and-then we have a service called gitlab shell 
and gab shell is where all the git-operations over SSH are 
managed so for instance if you clone a repository with-um a 
key pair that that's going to be run through KB-shell 
Workhorse is a reverse proxy load balancer and it handles a 
lot of the-large or long running operations so um if you 
look at this chart here you can-actually see that 
everything goes through Workhorse before it goes to the-web 
server it it kind of decides what goes the web server and 
what doesn't and-the example that I'll give is um and it 
might have changed it's been a while but-object storage 
used to go from Workhorse directly to S3 right so if you 
wanted to-uh check the logs on objects not being uploaded 
to S3 the Workhorse logs would-house set you wouldn't 
necessarily want your web server handling a large tar-file 
uh we use engine X in the front end too-so engine X sits in 
front of everything all web related stuff and determines 
if-something's going to git lab Pages or if it's going to 
Workhorse and then your-certificates are configured at 
engine X rules if you need-them gitlab Pages uh gitlab can 
serve static pages and they're served from S3-or object 
storage and then finally sidekick which is a background 
um-processor so sidekick jobs are stored in reddis and and 
uh you know the example I-gave the example I like to give 
and I don't know if this is still the case but-when you 
think of an action in gitlab like if you delete a user git 
lab-doesn't go and delete the user uh it creates a 
background job in redis that-says hey this user is to be 
deleted and then there is sidick processes that are-picking 
up these jobs and deleting these users it's uh very similar 
to how like-sqs and AWS would work any questions on the 
frontend-services okay back end so we got gy and this 
is-where all your source code is stored uh it used to also 
store Snippets it may-still um but uh your actual source 
code this that's on the gly-knowns we have prect so prect 
shows up in our 3K architectures and higher and-it's for 
high availability so prect does things like um you know 
ensuring that-there's replication on the gly nodes load 
balancing Val recover data-Integrity when a user makes a 
commit what prect will do if you have three G-Elite nodes 
prect will write that to two if that's what your 
replication factor-is and then check the hash to make sure 
that there's strong consistency across-the two and then 
Mark that as as you know both nodes were written at the 
same-time um if one node fails to write so you you have an 
outdated version of the-repository on one node and the 
other node for whatever reason is up to date-it'll will'll 
uh flag that node and put a background job in um to go back 
and-make sure that gets replicated we have reddis so redus 
does-all of our caching um it does data caching so it's 
used to frequently uh to-store frequently accessed data to 
reduce load in the database um you can think of-things like 
uh user information project metadata repository data um it 
does page-caching so uh certain pages are cached up to 
reduce or increase the rendering-speed if they're 
frequently accessed it houses our background jobs and then 
it-manages session management so when a user logs into 
gitlab rdus is what makes-sure that their session stay is 
held um as their load balcer might be moving-them to 
different fun end nodes uh console and just remember 
when-we showed that diagram before all of those are these 
components broken up in-different servers so you know we 
talk about the complexity of gitlab um it's-because there's 
so many services that have to be installed but console is 
uh-delivered as both the client and a server service and uh 
it's used for two-things it's used for monitoring so it'll 
collect Prometheus data um that can be-grafted with grafana 
which used to be shipped with-gitlab uh it also will keep 
an eye on the health of the postgress node and-elect a new 
leader so uh if we're deploying our own postgress solution 
in-a high availability scenario then console would go with 
it Sentinel is-very much like console it monitors redus 
rtis is H new Reedus-leaders Prometheus is for metrics 
monit so we have two pieces that-we install there's 
exporters and there's the promethus server uh and 
the-exporters will gather metrics on gitlab services and 
send them in so we can have-our graphs and dashboards to 
make sure that we're monitoring G-laab uh the database so 
we we use postgress in a lot of different areas in-get lab 
there's you know um you can have it for application you 
have to have one-for your application database uh if you 
have G cluster you have to have a gy-cluster database and 
then every Geo site has to have a postgress and you 
know-just uh funny start when I started we actually 
supported MySQL and postgress-uh but uh that just slowly 
was spaced out and then uh the last two servers on-here are 
in support of postr so PG bouncer helps us with uh 
database-pooling or uh connection pooling for the database 
and then along with the load-balance configuration and then 
Patron supports the failover-activities alongside console 
and PG bouncer-so we'll go right into talking through a 
reference-architecture so this is gitlab's 3K 
reference-architecture uh I think the EMS always ask why 
doesn't implementation with-gitlab cost so much um or why 
is there so much time that needs to happen with-it and it's 
because gitlab ha is complex so uh in this scenario we've 
got 25-servers two load balancers there's 8 S3 buckets uh 
in those buckets we you know-artifacts external discs 
uploads lfs packages dependency proxy terraform and-pages 
and when we talked about the front end-components we were 
talking about these components right-here um all of these 
represent our backend-components and we actually have a 
cost and uh calculator available now so-that's where I got 
this from so if a customer says how much is-this going to 
cost to deploy uh you can go here and share that cost in 
this-example is $29,000 just to deploy the VMS on AWS-for 
3K reference architecture this is not data storage this is 
not Network-traffic um Ingress and egress this is just 
straight up uh the VM size to spec-so so Kevin this is the 
cost Amazon this is the cloud cost yes sir yeah so you-got 
s new subscriptions all on top of this and obviously yeah 
yeah yeah and it-kind of goes back to that slide earlier 
you know when you when you start looking-at RTO and RPO and 
you want better results and customers want ha 
it's-expensive so this is the first 3K is where full ha 
starts with-gitlab where you have gly cluster so when 
customers come to us and they say-okay we have 50 
developers but we need ha you know sometimes I don't think 
they-understand that okay but can you manage 25 servers and 
take on-$330,000 in VM costs um is that worth ha for you or 
is a single node you know-with a single node Geo which we 
talk about later the right-solution and just finally it 
does does the level of subscription have an impact-on this 
design you know ultimate feature does that add more comp 
reputation power-maybe no no the biggest um drivers for 
ultimate have historically been plan and-secure yeah um but 
no I mean this is this is when a customer says hey I 
need-ha this is entry-level ha this is what they're 
asking-for okay cool and you can deploy this on gitlab's 
free product uh but we don't-support it so uh if we've had 
customers come and try to engage PS uh when they-were on 
gitlab free and and you know it's we don't we don't want to 
help them-build out something that normally would be a paid 
tier this they have to do on-their own I kind of want to 
show you what deploying to AWS and cloud services-can bring 
the table though so uh with AWS customers and the GB 
environment-tool supports this uh we can use services like 
elasticache and RDS to-significant reduce the footprint so 
uh we just took uh 12 servers out of the-Mex just by saying 
Hey I want to manage Reddit service to last cache uh so 
give-me an ha redish cluster and then the same goes to RDS 
I want a multi-az RDS-instance um so pretty significant 
reduction in-nodes and the next thing I want to point out 
too is this when a customer comes to-us and says I want to 
deploy with kubernetes-this section here is what's 
in-kubernetes all of these still have to be VMS now you can 
deploy these other-servers in Helm but the documentation 
says that it's Alpha it might be beta-now but it's not 
supporting a production environment and they should not 
be-running these components in Helm um for their git lab 
production deployment the-only servers that go into 
production are these front end nodes here so when we-talk 
to customers again going back to the smaller user counts 
you know they-might have 50 users 100 users and they say 
hey I want to run kubernetes what-they're really saying is 
is I still want to have but is this uh 18-VMS for my 12 
users but I want to add a kubernetes stack on top of that 
and-manage that as well um and and we try to discourage 
that until they get into the-much larger range you know I 
think uh the QA team recommends folks be at 3K or-higher 
Professional Services has seen success with Folks at 10,000 
or higher-with a dedicated kubernetes team um and I I'll 
kind of show you in a little bit-the advantages that 
kubernetes brings to the table um but the the 
biggest-disadvantage is that you also cannot do zero on 
time upgrades with kubernetes-so any questions okay-so one 
of the things we're learning with customers um and this is 
where I got to-not say names but uh you know traditionally 
we've always scoped-architectures based off user count you 
have 2,000 developers this is the-reference architecture 
for 2,000 users and that works that worked very well for-a 
long time um but we have customers that are kind of using 
gitlab in out of-thebox ways it's an automation tool with a 
lot of power-and um you know we had one scenario where they 
had 3,000 users but uh they-were using 25,000 users worth 
of load on the system you know and so when we're-scoping 
these These are the types of ones we want to ask the right 
questions-you know why do you need to expand your git lab 
footprint why are you moving to-the cloud um you know what 
do you running on today how is it performing-today and if 
we start to run into scenarios where we feel like a 
customer-might be uh using more than um the standard 
that's-something where we would want to do some Discovery 
and get fast STS and actually-start looking at the requests 
per second from their live production data uh then-just 
saying hey here's a 3,000 user architecture and uh you'll 
notice with-kubernetes it actually supports double the 
request per second for the-infrastructure so one of the 
advantages to kubernetes is is that it can scale um-those 
front-end you know API type servers very quickly the ones 
that-handle to get traffic and things like that um so you 
lose zero downtime-upgrades the complexity goes up uh but 
you do uh get better performance as a-whole and I shared 
the link in the notes for this for fast stats which is a 
tool-that you can use to collect this data any questions on 
this one and then-we'll get into Gio-cool all right so Geo 
so Geo can act and look like the-primary for Geographic 
distributed users they don't necessarily know that 
they're-on a Geon node and users can push and pull from Geo 
node um and what happens-is is that if a user is connected 
to a Geon node and they do a get push it-actually behind 
the scenes proxies it to the primary so if they're on this 
node-over here and they push to it it proxies it to the 
primary which writes it and-then replicates it back to the 
Geo node um and and for geographically-distributed users 
when they pull it pulls from the Geo node so uh if you-have 
you know your main site is in America's and I actually had 
a customer-like this they had a data center in Soul uh 
South Korea and uh when they were-cloning and fetching 
large repositories it was taking forever and when they 
set-up a Geo site that it went from you know um minutes to 
seconds to PO those-repositories you can uh balance the 
readon traffic 2 between your primary-and secondary sites 
you know we have another customer we're talking to now-that 
does significant amount of API calls against skab uh 
they're looking at-standing up Geo and and that is so that 
they can do all calls against the-secondary site the other 
thing to note is that Geo-can share a URL between your 
primary and your secondary so you can have a-separate URL 
for geo but you can also uh have a unified URL and then uh 
use some-uh geodns and load balancing to kind of distribute 
the users where they-go any questions on the what geod does 
from a distributor perspective no okay-uh so you can fail 
over pretty quickly with Gio I did it with one customer 
uh-they were 15,000 users and I was nervous and it happened 
almost instantaneously-like it's like one command now um 
it's gotten significantly easier than it used-to be so um 
when a customer wants to fail over it's just you know 
proing the-environment run the command and updating DNS uh 
unless it's a unified URL which-in case it'll just work 
Runner ERS automatically connect if they're still-up and 
running because the URL is the same and the tokens that 
they use are in-the database that's a read replica so uh 
you can you know with the proper-planning you can fil over 
very quickly to-go one of the limitations that you know 
when folks say well why can't we use Geo-as an ha solution 
uh and the reason is is just that the primary 
authenticates-the secondaries authenticate after off the 
primary so if your primary goes down-your GEOS actually go 
down um until you fail over and so they are not yeah-that's 
look um so just something to make sure you're aware of uh 
once you fail-over then they they totally work but uh when 
you authenticate against the geoc-secondary it actually 
sends it back to the primary to authenticate so you 
lose-that functionality if the primary goes down um the 
other thing I want to call-it too is is that the geoc 
secondaries and primary don't care what the other-one is so 
you you going have a single node primary and a 50k 
reference-architecture Geo don't do that that's crazy but 
you can have the other way-around too so uh you can have a 
3K reference architecture for your primary-site and uh 
single nodes on the goo and you can have multiple that way 
and the-only thing that it cares about is uh there needs to 
be a re replica of the-database which can be within the 
single node this is an AWS diagram so I have a-RDS re 
replica here and that the two front ends can talk to each 
other-because they communicate over apis and you know more 
often than not you're-going to have a smaller Geo depending 
on your ability to maintain-servers uh you know so keep in 
mind that a 3K reference architecture with 25-servers a 3K 
geo means you're managing 50 servers plus an additional 
tracking-database is there any kind of use case 
benefits-for by directional active active-so yes and no 
right so so active active to me is if one goes down the 
other one-works and we don't get passive okay yeah you've 
got two use you-to you can absolutely use both for sure 
yeah users you know if you've got users-all over the world 
and you want to distribute it they can use those 
other-sites now couple things to keep in mind they don't 
necessarily know this but the-rights that they make are 
actually going back to the primary so you want to make-sure 
your primary is big enough and to support your secondary 
nodes and those-secondaries will stop working if the 
primary goes down until you actually-perform a failover 
yeah so you can't you always have a primary you can't have 
a-two primaries replicating back to two secondaries across 
correct yeah okay-and I kind of touched this in the 
beginning but with with gitlab within-region within data 
center we can support ha um but we really can't support 
true-ha across different regions the other thing uh and 
it's-getting better but the recovery process from a g fover 
uh you have to rebuild-the original site uh and it might 
have changed I can double check the-documentation but 
historically let's say that you had a catastrophic outage 
on-your main site and you did a go over failover and your 
user is using this um-the process to go back would be to 
stand up a new primary site set it up as a Geo-secondary to 
your now promoted geoc secondary let it replicate then 
promote-your primary site again and then restand up your 
geoc secondary set it up as a-geoc secondary to your 
original primary site and then let that replicate as-well I 
mean you're back up and running your users didn't really 
miss a meat but-as an Sr or an admin you've got some work 
ahead of-you I have a question um what is the typical 
life-time for data replication and how do we ensure that um 
data Integrity is-ured so the data um Gio has well the lag 
time I'll tell you-right now is pretty quick it's it's it 
happens when pushes happen um usually I-find that it's it's 
within minutes if not faster uh you know there's 
caveat-right if a customer you know I had a customer that 
for some reason was-pushing like isos to repositories which 
is a whole another conversation but-that's not the point 
right um if they push a 10 gig ISO to-the GEOS secondary 
you know they just have to be aware that it's not going 
to-write to the geoc secondary it's going to be sent over 
the primary to Bright in-the primary um and if they're in 
America and South Korea that might take-a while and then 
it's going to replicate to the geosite so things like that 
would-take a while but if you think of your average get 
commit and push there's not-a lot it's it's text right it's 
code it's it's very quick it's not like you-you know in one 
commit I'll push a gig of code um so it's very very quick 
and-as far as the consistency goes um gilb there's a-table 
and I'll see if I can find it I can follow up but um-so can 
I just add here Kevin Yeah Yeah so basically for Gio uh you 
know there-is a dashboard that you can see on the UI itself 
and the replication keeps-going on um and you can make sure 
that you know that is up to 100% it'll show-you both the 
primary and the secondary site um and you can just make 
sure that-you see it's in 100% sync and only once in sync 
you can just just do the-failover I can probably try uh 
seeing if I have my setup on and I can share a-screenshot 
probably yeah that would be awesome and while she's looking 
at that-let me know I'll switch the presenter to you um 
I'll find it there's a table for-the different data types 
and how G checks consistency so um use hash it's-it's 
validated okay um the other thing to-call out too 
especially when we talk about Cloud environments is is that 
Gio-will replicate object storage for you um so if you're 
going from AWS to gcp or-something like that you know Gio 
can manage that for you uh but more often-than that when 
you're working in Cloud environments like AWS they have 
cross-region replication with buckets and you can also just 
set that up and let Amazon-handle your replication of 
buckets any other questions on-Gio just one so that's your 
use case can you use Goo you can use Geo right to-migrate 
can't you if if you've already got a Geo-environment 
running and you want to migrate using Goo is that is 
that-limited is that a limitation yeah when you you have 
go-link coming in to do the migration it's like Hub and 
spoke you know you have-your Central Primary and you can 
have as many Geo nodes as you want and they can-be as big 
or small as you want to right you can you can have a 3K 
reference-architecture and then you can say I want one 
single node Geo in South Korea soul-and I'm going to take 
snapshots of that and that's just uh you know just just 
in-case and then I might put another full 3K on the west 
coast if I'm in the east-coast so that I can fail over to 
that okay and they can all go into the-single instance they 
all go into the single instance the caveat is is that-when 
you fail over to a secondary all of the other GEOS 
become-or they don't follow yeah yeah so you you would you 
would want to hook them up-yeah brilliant thank you and um 
here's the data types and the verification-replication 
method so it's a pretty cool table um and and you know 
especially-recently I don't think there's anything that 
they don't have some kind of strong-consistency 
verification for the data type this is also a great chart 
if-you're sculping with a customer and they say does geom 
replicate because there in-the past had been items or if 
new object types come into play like when terraform-State 
files first came into play for instance I don't think it 
immediately-was supported by Gio as a replication type so 
customers ask hey can you-support you replicate this type 
to the secondary site you know this table right-here and I 
I'll drop the link in the chat and then uh going on to the 
last-slide here I just wanted to kind of sh I share this 
with Partners too I think-this is pretty cool anybody 
especially within gitlab can uh-go check out our gitlab 
environment toolkit uh if you need help I can show-you how 
you can create a cloud account at kit laab and um we have a 
a a-implementation Services learning path which is free uh 
for everybody uh gitlab-employees and customers they can go 
and take this online course that education-provides and 
then they can run through our Hands-On Workshop which I 
think is-internal on but we do you know set it up for 
partners and things like that which-is a g laab issue that 
walks you through um deploying a 3K reference 
architecture-in AWS just make sure you delete it when 
you're done because it's $330,000 a-year so any any 
questions on that-cool Jenice if you have it I'll let you 
show it if not we can probably cut it-no so I have a 
screenshot probably I can show uh does they have any 
customer-names that's what I was checking no this is on my 
sample so yeah I can share-this I mean I have anyway 
destroyed this environment so it's it's okay but it's-just 
a screenshot uh sharing my screen are we recording because 
the it's on-yeah it's streaming live to YouTube Glen's got 
us coverage-okay keep it safe I don't want to share 
probably on-the live stream it's okay let's not we can stop 
the recording in the chair-that's fine I'd rather like CL 
said keep it safe than yeah make a mistake yeah-you can 
just say it offl yeah excellent thank you Kevin very 
much-for that any other questions comments it says it's 
still live on YouTube it is it-is okay yeah before I want 
to make sure-we've got everything covered that we can talk 
about and then uh then-we'll go to the private portion so 
any other questions comments uh I will I'll-will up the do 
update the documentation Kevin you can send me the link to 
your-presentation I can drop it in there as well and if 
anyone has questions that-they want to answer drop them in 
the doc as a comment and we can get we can get-to those as 
well otherwise I will stop the live-stream portion of this 
thanks again Kevin very much appreciate it
